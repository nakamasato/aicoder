package planner

import (
	"bytes"
	"context"
	_ "embed"
	"encoding/json"
	"fmt"
	"strings"
	"text/template"

	"github.com/nakamasato/aicoder/internal/file"
	"github.com/openai/openai-go"
)

//go:embed templates/investigation_prompt.tmpl
var InvestigationPromptTemplate string

type InvestigationResult struct {
	TargetFiles    []string `json:"target_files" jsonschema_description:"List of files that are necessary to modify. The files generated by aicoder must not be included. e.g. repo_structure.json, repo_summary.json, etc."`
	ReferenceFiles []string `json:"reference_files" jsonschema_description:"List of files that are necessary to refer to determine modification."`
	Result         string   `json:"result" jsonschema_description:"The result of the investigation. Please provide the necessary information or pieces of contents from the relevant files."`
}

func (ir InvestigationResult) String() string {
	return fmt.Sprintf("Target Files: %v\nReference Files: %v\nResult: %s", ir.TargetFiles, ir.ReferenceFiles, ir.Result)
}

func generateInvestigationPrompt(query string, files []file.File, examples []InvestigationResultExample) (string, error) {
	// Prepare data for the template
	data := struct {
		OriginalQuery string
		RelevantFiles []file.File
		Examples      []InvestigationResultExample
	}{
		OriginalQuery: query,
		RelevantFiles: files,
		Examples:      examples,
	}

	// Execute the template
	tmpl, err := template.New("examples").Funcs(template.FuncMap{
		"add": func(a, b int) int { return a + b },
	}).Parse(InvestigationPromptTemplate)
	if err != nil {
		return "", err
	}

	var buf bytes.Buffer
	if err := tmpl.Execute(&buf, data); err != nil {
		return "", err
	}
	return buf.String(), nil
}

// 3. Investigation Step
func (p *Planner) executeInvestigation(ctx context.Context, query string, steps []string, files []file.File) (string, error) {
	var investigationResultStr strings.Builder
	for i, step := range steps {
		fmt.Printf("Investigation Step %d: %s\n", i+1, step)
		// identify files to check for collect information
		investigationFiles, err := p.removeUnrelevantFiles(ctx, step, files)
		if err != nil {
			return "", fmt.Errorf("failed to remove irrelevant files: %w", err)
		}
		fmt.Printf("Investigation Step %d: Relevant files: %d\n", i+1, len(investigationFiles))

		// generate completion for investigation step
		prompt, err := generateInvestigationPrompt(query, investigationFiles, DefaultInvestigationExamples)
		if err != nil {
			return "", fmt.Errorf("failed to generate prompt for investigation step %d: %w", i+1, err)
		}

		res, err := p.llmClient.GenerateCompletion(ctx, []openai.ChatCompletionMessageParamUnion{
			openai.SystemMessage(prompt),
			openai.UserMessage(fmt.Sprintf(`Investigation theme: %s`, step)),
		}, InvestigationResultSchemaParam)
		if err != nil {
			return "", fmt.Errorf("failed to generate completion for investigation step %d: %w", i+1, err)
		}
		fmt.Printf(`Investigation Step %d:
	step: %s
	result: %s\n`, i+1, step, res) // too long

		var result InvestigationResult
		if err = json.Unmarshal([]byte(res), &result); err != nil {
			return "", fmt.Errorf("failed to generate completion for investigation step %d: %w", i+1, err)
		}
		investigationResultStr.WriteString(fmt.Sprintf("\n--- %d ---\nInvestigation: %s\nTarget files:\n%s\nReference files:\n%s\nResult:\n%s\n--- %d end ---\n", i, step, result.TargetFiles, result.ReferenceFiles, result.Result, i))
	}

	return investigationResultStr.String(), nil
}
