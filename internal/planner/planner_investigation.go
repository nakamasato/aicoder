package planner

import (
	"context"
	"encoding/json"
	"fmt"
	"strings"

	"github.com/nakamasato/aicoder/internal/file"
	"github.com/openai/openai-go"
)

const InvestigationPrompt = `You are a helpful assistant to generate the investigation result based on the collected information.
Your investigation result will be used to plan the actual file changes in the next steps.
So you need to collect information that is relevant to the original query and the goal.

Original query: %s

--- Relevant files ---
%s
--- Relevant files ---

================= Examples start =================
%s
================= Examples end ===================

Please generate the investigation result based on the collected information.
This investigation is to extract the necessary information to plan the actual file changes in the next steps.
The output is the information that is necessary to determine the actual file changes in the next step.

`

type InvestigationResult struct {
	TargetFiles    []string `json:"target_files" jsonschema_description:"List of files that are necessary to modify. The files generated by aicoder must not be included. e.g. repo_structure.json, repo_summary.json, etc."`
	ReferenceFiles []string `json:"reference_files" jsonschema_description:"List of files that are necessary to refer to determine modification."`
	Result         string   `json:"result" jsonschema_description:"The result of the investigation. Please provide the necessary information or pieces of contents from the relevant files."`
}

func (ir InvestigationResult) String() string {
	return fmt.Sprintf("Target Files: %v\nReference Files: %v\nResult: %s", ir.TargetFiles, ir.ReferenceFiles, ir.Result)
}

// 3. Investigation Step
func (p *Planner) executeInvestigation(ctx context.Context, query string, steps []string, files []file.File) (string, error) {
	exampleStr, err := convertInvestigationResultExamplesToStr(DefaultInvestigationExamples)
	if err != nil {
		return "", fmt.Errorf("failed to convert investigation result examples to string: %w", err)
	}
	var investigationResultStr strings.Builder
	for i, step := range steps {
		fmt.Printf("Investigation Step %d: %s\n", i+1, step)
		// identify files to check for collect information
		investigationFiles, err := p.removeUnrelevantFiles(ctx, step, files)
		if err != nil {
			return "", fmt.Errorf("failed to remove irrelevant files: %w", err)
		}
		fmt.Printf("Investigation Step %d: Relevant files: %d\n", i+1, len(investigationFiles))

		// generate the investigation result for the step
		var builder strings.Builder
		for _, file := range investigationFiles {
			builder.WriteString(fmt.Sprintf("\n--- %s start ---\n%s\n--- %s end ---\n", file.Path, file.Content, file.Path))
		}

		res, err := p.llmClient.GenerateCompletion(ctx, []openai.ChatCompletionMessageParamUnion{
			openai.SystemMessage(fmt.Sprintf(InvestigationPrompt, query, builder.String(), exampleStr)),
			openai.UserMessage(fmt.Sprintf(`Investigation theme: %s`, step)),
		}, InvestigationResultSchemaParam)
		if err != nil {
			return "", fmt.Errorf("failed to generate completion for investigation step %d: %w", i+1, err)
		}
		fmt.Printf(`Investigation Step %d:
	step: %s
	result: %s\n`, i+1, step, res) // too long

		var result InvestigationResult
		if err = json.Unmarshal([]byte(res), &result); err != nil {
			return "", fmt.Errorf("failed to generate completion for investigation step %d: %w", i+1, err)
		}
		investigationResultStr.WriteString(fmt.Sprintf("\n--- %d ---\nInvestigation: %s\nTarget files:\n%s\nReference files:\n%s\nResult:\n%s\n--- %d end ---\n", i, step, result.TargetFiles, result.ReferenceFiles, result.Result, i))
	}

	return investigationResultStr.String(), nil
}
